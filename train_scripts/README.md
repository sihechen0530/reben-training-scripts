# SLURM Training Infrastructure

è¿™ä¸ªç›®å½•åŒ…å«äº†åœ¨ SLURM é›†ç¾¤ä¸Šå¯åŠ¨ BigEarthNet ä»¥åŠå¤šæ¨¡æ€è®­ç»ƒä»»åŠ¡æ‰€éœ€çš„ä¸€åˆ‡ï¼šé…ç½®æ¨¡æ¿ã€æäº¤è„šæœ¬ã€sbatch æ¨¡æ¿ã€ç¯å¢ƒè„šæœ¬ç­‰ã€‚æœ¬æ–‡æ¡£æ•´åˆäº† `MULTI_CONFIG_USAGE.md` ä¸ `SETUP_DINOV3.md` çš„æ‰€æœ‰ä¿¡æ¯ï¼Œåªä¿ç•™ä¸€ä¸ªæƒå¨çš„ READMEã€‚

## ğŸ§­ å¿«é€Ÿå¯¼èˆª

- [ğŸ“ å…³é”®æ–‡ä»¶](#-å…³é”®æ–‡ä»¶)
- [ğŸš€ å¿«é€Ÿå¼€å§‹](#-å¿«é€Ÿå¼€å§‹)
- [ğŸ“‹ é…ç½®æ–‡ä»¶è¯¦è§£](#-é…ç½®æ–‡ä»¶è¯¦è§£)
- [ğŸ§© å¤šé…ç½®æ–‡ä»¶æ‰¹é‡æäº¤](#-å¤šé…ç½®æ–‡ä»¶æ‰¹é‡æäº¤)
- [ğŸ¦¾ DINOv3 è®¾ç½®æŒ‡å—](#-dinov3-è®¾ç½®æŒ‡å—)
- [ğŸ”€ å¤šæ¨¡æ€è®­ç»ƒ](#-å¤šæ¨¡æ€è®­ç»ƒ)
- [âš¡ï¸ å¤š-GPU-è®­ç»ƒ](#ï¸-å¤š-gpu-è®­ç»ƒ)
- [ğŸ“Š ç›‘æ§ä¸ä½œä¸šç®¡ç†](#-ç›‘æ§ä¸ä½œä¸šç®¡ç†)
- [ğŸ› å¸¸è§é—®é¢˜](#-å¸¸è§é—®é¢˜)
- [ğŸ“š ç¤ºä¾‹å·¥ä½œæµ](#-ç¤ºä¾‹å·¥ä½œæµ)
- [ğŸ”— ç›¸å…³æ–‡ä»¶](#-ç›¸å…³æ–‡ä»¶)

## ğŸ“ å…³é”®æ–‡ä»¶

- **`config.yaml`**ï¼šä¸»é…ç½®æ–‡ä»¶ï¼Œç»Ÿä¸€ç®¡ç†ä½œä¸šå‚æ•°ã€ç¯å¢ƒå˜é‡ã€æ•°æ®è·¯å¾„ä¸è®­ç»ƒå‚æ•°
- **`submit.py`**ï¼šPython æäº¤è„šæœ¬ï¼Œè¯»å–é…ç½®å¹¶ç”Ÿæˆ/æäº¤ sbatch ä½œä¸š
- **`sbatch_train.sbatch`**ï¼šSLURM æ‰¹å¤„ç†è„šæœ¬æ¨¡æ¿
- **`env_setup.sh`**ï¼šç¯å¢ƒåˆå§‹åŒ–è„šæœ¬ï¼ˆåŠ è½½ CUDAã€condaã€HF token ç­‰ï¼‰

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å‡†å¤‡é…ç½®

ç¼–è¾‘ `config.yaml` ä»¥åŒ¹é…ä½ çš„é›†ç¾¤ä¸æ•°æ®ç¯å¢ƒï¼š

```yaml
job:
  partition: gpu
  account: your_account
  chdir: "/path/to/reben-training-scripts"
  mail_user: "you@email.com"

data:
  benv2_data_dir: "/path/to/BigEarthNet/data"

train:
  args:
    architecture: "resnet18"
    batch_size: 32
    epochs: 100
    lr: 0.001
```

### 2. æäº¤å•ä¸ªè®­ç»ƒä½œä¸š

```bash
cd train_scripts
python submit.py
```

### 3. å¯ç”¨è¶…å‚æœç´¢ï¼ˆSweepï¼‰

```yaml
train:
  sweep:
    grid:
      lr: [0.001, 0.0003, 0.0001]
      batch_size: [32, 64, 128]
      seed: [42, 123, 456]
```

```bash
python submit.py --sweep
```

### 4. é¢„è§ˆä¸æäº¤ï¼ˆDry Runï¼‰

```bash
python submit.py --dry-run
python submit.py --sweep --dry-run
```

## ğŸ“‹ é…ç½®æ–‡ä»¶è¯¦è§£

### Job é…ç½®
```yaml
job:
  name: bigearthnet-ft
  partition: gpu
  qos: normal
  time: "08:00:00"
  nodes: 1
  gpus_per_task: 1
  cpus_per_task: 8
  mem: "32G"
  constraint: "a100|v100"
```

### æ•°æ®é…ç½®
```yaml
data:
  benv2_data_dir: "/path/to/data"
```

### è®­ç»ƒå‚æ•°
```yaml
train:
  args:
    architecture: "resnet18"
    bandconfig: "all"   # all, s2, s1, rgb
    batch_size: 32
    epochs: 100
    lr: 0.001
    seed: 42
    use_wandb: false
    config: "../train_scripts/config.yaml"
```

### è¶…å‚æœç´¢å†™æ³•

**æ–¹å¼ 1ï¼šç½‘æ ¼æœç´¢**
```yaml
sweep:
  grid:
    lr: [0.001, 0.0003]
    batch_size: [32, 64]
    seed: [42, 123]
```

**æ–¹å¼ 2ï¼šåˆ—è¡¨æ–‡ä»¶**
```yaml
sweep:
  list_file: "sweeps.txt"
```

`sweeps.txt` ç¤ºä¾‹ï¼š
```yaml
{lr: 0.001, batch_size: 32, seed: 42}
{lr: 0.0003, batch_size: 64, seed: 123}
{lr: 0.0001, batch_size: 128, seed: 456}
```

## ğŸ§© å¤šé…ç½®æ–‡ä»¶æ‰¹é‡æäº¤

`submit.py` æ”¯æŒä¸€æ¬¡æ€§æäº¤å¤šä¸ªé…ç½®å¹¶ä¸”æ¯ä¸ªé…ç½®éƒ½å¯ä»¥è‡ªå¸¦ sweepã€‚

### åŸºæœ¬å‘½ä»¤

```bash
# å•é…ç½®ï¼ˆæ—§æ–¹å¼ï¼‰
python submit.py --config config.yaml

# å¤šé…ç½®ï¼ˆæ–°æ–¹å¼ï¼‰
python submit.py --config cfg_small.yaml cfg_base.yaml cfg_large.yaml

# ä½¿ç”¨é€šé…ç¬¦
python submit.py --config config_dinov3_*.yaml

# ä¸ºæ¯ä¸ªé…ç½®å¯ç”¨ sweep
python submit.py --config cfg_small.yaml cfg_base.yaml --sweep

# ä»…é¢„è§ˆ
python submit.py --config cfg_*.yaml --dry-run
```

### å…¸å‹åœºæ™¯

**åœºæ™¯ 1ï¼šä¸åŒæ¶æ„çš„å¯¹æ¯”å®éªŒ**

```bash
python submit.py --config \
  config_dinov3_small_lp.yaml \
  config_dinov3_base_lp.yaml \
  config_dinov3_large_lp.yaml
```

è¾“å‡ºæ‘˜è¦ç¤ºä¾‹ï¼š
```
Using template: sbatch_train.sbatch
Using 3 config file(s):
  - config_dinov3_small_lp.yaml
  - config_dinov3_base_lp.yaml
  - config_dinov3_large_lp.yaml

============================================================
Processing config [1/3]: config_dinov3_small_lp.yaml
... 2760501
Processing config [2/3]: config_dinov3_base_lp.yaml
... 2760502
Processing config [3/3]: config_dinov3_large_lp.yaml
... 2760503
============================================================
SUBMISSION SUMMARY
Total jobs submitted: 3
  [config_dinov3_small_lp.yaml] â†’ Job 2760501
  [config_dinov3_base_lp.yaml] â†’ Job 2760502
  [config_dinov3_large_lp.yaml] â†’ Job 2760503
============================================================
```

**åœºæ™¯ 2ï¼šæ¯ä¸ªé…ç½®è‡ªè¡Œ sweep**

```bash
python submit.py --config config_dinov3_small_lp.yaml config_dinov3_base_lp.yaml --sweep
```

- small é…ç½®è‡ªå¸¦ `lr Ã— bs` å…± 4 ä¸ªä»»åŠ¡
- base é…ç½®è‡ªå¸¦ `lr Ã— drop_rate` å…± 4 ä¸ªä»»åŠ¡
- æ€»è®¡ 8 ä¸ª sbatch

**åœºæ™¯ 3ï¼šDry Run æ ¡éªŒ**

```bash
python submit.py --config config_*.yaml --dry-run
```

### è¾“å‡ºç›®å½•ç»“æ„

```
/scratch/zhou.lihan/experiments/
â”œâ”€â”€ small_model/
â”‚   â”œâ”€â”€ 2760501/
â”‚   â”‚   â”œâ”€â”€ checkpoints/
â”‚   â”‚   â”œâ”€â”€ config.yaml
â”‚   â”‚   â”œâ”€â”€ slurm.out
â”‚   â”‚   â””â”€â”€ slurm.err
â”œâ”€â”€ base_model/
â”‚   â””â”€â”€ 2760502/
â””â”€â”€ large_model/
    â””â”€â”€ 2760503/
```

### å…³é”®å‚æ•°

- `--config`: å¤šä¸ªæ–‡ä»¶æˆ–é€šé…ç¬¦ï¼Œé»˜è®¤ `config.yaml`
- `--sweep`: å¯¹æ¯ä¸ªé…ç½®å¯ç”¨ `train.sweep`
- `--dry-run`: ä»…ç”Ÿæˆ sbatchï¼Œä¸æäº¤
- `--template`: æŒ‡å®š `sbatch` æ¨¡æ¿ï¼Œé»˜è®¤ `sbatch_train.sbatch`

### æœ€ä½³å®è·µ

1. **å‘½åè§„èŒƒ**ï¼š`config_dinov3_small_lp.yaml`ã€`config_multimodal_s2s1.yaml` ç­‰
2. **ç‰ˆæœ¬æ§åˆ¶**ï¼š`git add train_scripts/config_*.yaml`
3. **è¾“å‡ºéš”ç¦»**ï¼šä¸ºæ¯ç±»å®éªŒè®¾ç½®ç‹¬ç«‹ `job.output_dir`
4. **Dry Run ä¼˜å…ˆ**ï¼šæ‰¹é‡æäº¤å‰ä»¥ `less` æ£€æŸ¥ç”Ÿæˆçš„è„šæœ¬

### æ•…éšœæ’æŸ¥

- é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼šè„šæœ¬ä¼šç›´æ¥æŠ¥é”™å¹¶ç»ˆæ­¢ï¼Œä¿è¯ä¸ä¼šæäº¤ä»»ä½•ä½œä¸š
- job name é‡å¤ï¼šSLURM å…è®¸ï¼Œä½†å»ºè®®åœ¨é…ç½®ä¸­åŒºåˆ† `job.name`
- æ‰¹é‡å–æ¶ˆï¼šä½¿ç”¨æ€»ç»“é‡Œçš„ Job ID â†’ `scancel 2760501 2760502 2760503`

## ğŸ¦¾ DINOv3 è®¾ç½®æŒ‡å—

### 1. è·å– Hugging Face Token
1. ç™»å½• [Hugging Face](https://huggingface.co/)
2. Settings â†’ Access Tokens â†’ New token
3. å¤åˆ¶å½¢å¦‚ `hf_xxxxxxxxx` çš„ token

### 2. é…ç½® Token

**æ–¹å¼ 1ï¼š`env_setup.sh`ï¼ˆæœ¬åœ°/äº¤äº’å¼æ¨èï¼‰**
```bash
export HF_TOKEN="hf_xxxxxxxxxxxxxxxxxxxxx"
```

**æ–¹å¼ 2ï¼š`config.yaml`ï¼ˆSLURM ä½œä¸šæ¨èï¼‰**
```yaml
env:
  HF_TOKEN: "hf_xxxxxxxxxxxxxxxxxxxxx"
  OMP_NUM_THREADS: 8
  TOKENIZERS_PARALLELISM: "false"
```

### 3. å¯ç”¨ DINOv3 æ¨¡å‹

```yaml
train:
  args:
    architecture: "dinov3-base"   # small | base | large | giant
    bandconfig: "s2"
    bs: 32
    epochs: 10
    lr: 0.001
    # linear_probe: true  # ä»…è®­ç»ƒåˆ†ç±»å¤´
```

### 4. å¯ç”¨æ¨¡å‹åˆ—è¡¨

- `dinov3-small`  â†’ facebook/dinov3-vits16-pretrain-lvd1689m (384 dim)
- `dinov3-base`   â†’ facebook/dinov3-vitb16-pretrain-lvd1689m (768 dim)
- `dinov3-large`  â†’ facebook/dinov3-vitl16-pretrain-lvd1689m (1024 dim)
- `dinov3-giant`  â†’ facebook/dinov3-vitg16-pretrain-lvd1689m (1536 dim)

### 5. æäº¤å‘½ä»¤å‚è€ƒ

```bash
python submit.py              # å•æ¬¡è®­ç»ƒ
python submit.py --sweep      # è¶…å‚æœç´¢
python submit.py --dry-run    # é¢„è§ˆ
```

### 6. æ³¨æ„äº‹é¡¹

- âš ï¸ ä¸è¦æŠŠ token commit åˆ° Git
- token å»ºè®®æ”¾å…¥ç¯å¢ƒå˜é‡æˆ–ç§æœ‰ `.env`
- è®¤è¯å¤±è´¥æ—¶å…ˆç¡®è®¤ token æ˜¯å¦ç”Ÿæ•ˆ
- DINOv3 å‚æ•°é‡å¤§ï¼Œå¯¹ GPU/æ˜¾å­˜è¦æ±‚æ˜¾è‘—é«˜äº ResNet

### ResNet vs DINOv3

| ç‰¹æ€§ | ResNet18 | DINOv3-base |
|------|----------|-------------|
| å‚æ•°é‡ | ~11M | ~86M |
| Token éœ€æ±‚ | âŒ | âœ… |
| GPU å†…å­˜ | ~2-4GB | ~8-12GB |
| è®­ç»ƒé€Ÿåº¦ | å¿« | ç›¸å¯¹æ…¢ |
| æ€§èƒ½ | åŸºçº¿ | é€šå¸¸æ›´å¥½ |

## ğŸ”€ å¤šæ¨¡æ€è®­ç»ƒ

æ”¯æŒå¤š backbonesã€èåˆç­–ç•¥ä¸åˆ†ç±»å™¨ã€‚å…³é”®æ­¥éª¤ï¼š

1. åˆ‡æ¢è„šæœ¬ï¼š
   ```yaml
   train:
     script: "train_multimodal.py"
   ```
2. åœ¨ `multimodal_args` ä¸­é…ç½® backboneã€èåˆã€åˆ†ç±»å™¨ã€æ•°æ®è®¾ç½®ï¼ˆè§ä¸‹ä¾‹ï¼‰ã€‚
3. æ ¹æ®éœ€è¦æ·»åŠ  sweepï¼š
   ```yaml
   sweep:
     grid:
       fusion_type: ["concat", "weighted", "linear_projection"]
       classifier_type: ["linear", "mlp"]
       dinov3_freeze: [true, false]
       resnet_freeze: [true, false]
   ```

å¸¸ç”¨ç‰‡æ®µï¼š

```yaml
multimodal_args:
  dinov3_freeze: true
  resnet_freeze: true
  fusion_type: "concat"
  classifier_type: "linear"
```

```yaml
multimodal_args:
  fusion_type: "weighted"
  classifier_type: "mlp"
  classifier_hidden_dim: 512
```

```yaml
multimodal_args:
  use_s1: true  # è®© ResNet åŒæ—¶å¤„ç† S1 + S2
```

## âš¡ï¸ å¤š GPU è®­ç»ƒ

å€ŸåŠ© PyTorch Lightningï¼š

```yaml
job:
  gres: "gpu:v100-sxm2:4"
  mem: "64G"
  cpus_per_task: 16

train:
  args:
    devices: 4
    strategy: "ddp"
    bs: 512          # æ¯ GPU batch
    lr: 0.004        # çº¿æ€§ç¼©æ”¾
    workers: 16
```

è¦ç‚¹ï¼š

1. `bs` æ˜¯æ¯å— GPU çš„ batch sizeï¼Œæ€» batch = `bs * devices`
2. å­¦ä¹ ç‡é€šå¸¸æŒ‰ GPU æ•°é‡çº¿æ€§æ”¾å¤§
3. `workers â‰ˆ devices * (2~4)`
4. æå‰åœ¨ `job.gres` / `job.mem` ä¸­ç”³è¯·è¶³å¤Ÿèµ„æº
5. å¸¸è§ç­–ç•¥ï¼š`ddp`ï¼ˆæ¨èï¼‰ã€`ddp_spawn`ã€`deepspeed`ã€`fsdp`

å¸¸è§é—®é¢˜ï¼šOOM â†’ é™ä½ `bs` / å¢åŠ  `mem`ï¼›NCCL é”™è¯¯ â†’ ä¿è¯å•èŠ‚ç‚¹ + ç½‘ç»œé…ç½®ï¼›æé€Ÿä¸æ˜æ˜¾ â†’ å¢å¤§ batchã€æå‡æ•°æ®åŠ è½½èƒ½åŠ›ã€‚

## ğŸ“Š ç›‘æ§ä¸ä½œä¸šç®¡ç†

```bash
squeue -u $USER          # ä½œä¸šé˜Ÿåˆ—
squeue -j JOB_ID         # å•ä¸ªä½œä¸š
scancel JOB_ID           # å–æ¶ˆä½œä¸š
tail -f logs/*.out       # å®æ—¶æŸ¥çœ‹è¾“å‡º
tail -f logs/*.err       # æŸ¥çœ‹é”™è¯¯
```

## ğŸ› å¸¸è§é—®é¢˜

1. **ä½œä¸šå¤±è´¥**ï¼šæ£€æŸ¥ `logs/<job>.err`ï¼›ç¡®è®¤æ•°æ®è·¯å¾„ï¼›ç¡®ä¿ `env_setup.sh` å¯åŠ¨äº†æ­£ç¡®çš„ conda ç¯å¢ƒã€‚
2. **æ•°æ®è·¯å¾„é”™è¯¯**ï¼šä¼˜å…ˆè¯»å–é…ç½®é‡Œçš„ `data.benv2_data_dir`ï¼Œå¦åˆ™æ ¹æ® hostname æ¨æ–­ï¼Œæœ€åæ‰ä½¿ç”¨é»˜è®¤å€¼ã€‚
3. **`sbatch` æ‰¾ä¸åˆ°**ï¼šç¡®è®¤å¤„äº SLURM èŠ‚ç‚¹å¹¶ `module load slurm`ã€‚
4. **å¤šé…ç½®æäº¤å‡ºé”™**ï¼šè‹¥ä»»ä¸€é…ç½®æ–‡ä»¶ä¸å­˜åœ¨è„šæœ¬ä¼šç«‹å³æŠ¥é”™ï¼›ç¡®ä¿æ‰€æœ‰é…ç½®å¯è¯»ä¸” `job.output_dir` ä¸å†²çªã€‚
5. **æ‰¹é‡å–æ¶ˆ**ï¼šä½¿ç”¨æ€»ç»“é‡Œæ‰“å°å‡ºçš„ Job IDs â†’ `scancel {id1..idN}`ã€‚

## ğŸ“š ç¤ºä¾‹å·¥ä½œæµ

### å•æ¬¡å®éªŒ
```bash
vim config.yaml
python submit.py --dry-run
python submit.py
squeue -u $USER
tail -f logs/bigearthnet-ft-*.out
```

### è¶…å‚æ•°æœç´¢
```bash
vim config.yaml                # ç¼–è¾‘ train.sweep.grid
python submit.py --sweep --dry-run
python submit.py --sweep
watch -n 10 squeue -u $USER
```

## ğŸ”— ç›¸å…³æ–‡ä»¶

- è®­ç»ƒè„šæœ¬ï¼š`../scripts/train_BigEarthNetv2_0.py`
- å¤šæ¨¡æ€è„šæœ¬ï¼š`../scripts/train_multimodal.py`
- å®ç”¨å‡½æ•°ï¼š`../scripts/utils.py`
- é¡¹ç›®æ€» READMEï¼š`../README.md`
