# SLURM Training Infrastructure

è¿™ä¸ªç›®å½•åŒ…å«äº†ç”¨äºåœ¨SLURMé›†ç¾¤ä¸Šæäº¤BigEarthNetè®­ç»ƒä»»åŠ¡çš„åŸºç¡€è®¾æ–½ä»£ç ã€‚

## ğŸ“ æ–‡ä»¶è¯´æ˜

- **`config.yaml`** - ä¸»é…ç½®æ–‡ä»¶ï¼ŒåŒ…å«ä½œä¸šå‚æ•°ã€ç¯å¢ƒå˜é‡ã€æ•°æ®è·¯å¾„å’Œè®­ç»ƒå‚æ•°
- **`submit.py`** - Pythonæäº¤è„šæœ¬ï¼Œè¯»å–é…ç½®å¹¶æäº¤SLURMä½œä¸š
- **`sbatch_train.sbatch`** - SLURMæ‰¹å¤„ç†è„šæœ¬æ¨¡æ¿
- **`env_setup.sh`** - ç¯å¢ƒè®¾ç½®è„šæœ¬ï¼ˆåŠ è½½CUDAã€condaç­‰ï¼‰

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. é…ç½®ç¯å¢ƒ

ç¼–è¾‘ `config.yaml` æ–‡ä»¶ï¼Œè®¾ç½®ä½ çš„é›†ç¾¤å‚æ•°ï¼š

```yaml
job:
  partition: gpu          # ä½ çš„GPUåˆ†åŒºå
  account: your_account   # ä½ çš„è´¦å·
  chdir: "/path/to/reben-training-scripts"
  mail_user: "your@email.com"

data:
  benv2_data_dir: "/path/to/BigEarthNet/data"

train:
  args:
    architecture: "resnet18"
    batch_size: 32
    epochs: 100
    # ... å…¶ä»–è®­ç»ƒå‚æ•°
```

### 2. æäº¤å•ä¸ªè®­ç»ƒä»»åŠ¡

```bash
cd train_scripts
python submit.py
```

### 3. æäº¤è¶…å‚æ•°æœç´¢ä»»åŠ¡

åœ¨ `config.yaml` ä¸­é…ç½®sweepç½‘æ ¼ï¼š

```yaml
train:
  sweep:
    grid:
      lr: [0.001, 0.0003, 0.0001]
      batch_size: [32, 64, 128]
      seed: [42, 123, 456]
```

ç„¶åæäº¤ï¼š

```bash
python submit.py --sweep
```

è¿™ä¼šè‡ªåŠ¨ç”Ÿæˆæ‰€æœ‰å‚æ•°ç»„åˆï¼ˆç¬›å¡å°”ç§¯ï¼‰å¹¶æäº¤ç‹¬ç«‹çš„ä½œä¸šã€‚

### 4. é¢„è§ˆä¸æäº¤ï¼ˆDry Runï¼‰

```bash
# é¢„è§ˆå•ä¸ªä½œä¸š
python submit.py --dry-run

# é¢„è§ˆsweepä½œä¸š
python submit.py --sweep --dry-run
```

## ğŸ“‹ é…ç½®æ–‡ä»¶è¯¦è§£

### Jobé…ç½®
```yaml
job:
  name: bigearthnet-ft     # ä½œä¸šåç§°
  partition: gpu           # SLURMåˆ†åŒº
  qos: normal             # QoSé˜Ÿåˆ—
  time: "08:00:00"        # æœ€å¤§è¿è¡Œæ—¶é—´
  nodes: 1                # èŠ‚ç‚¹æ•°
  gpus_per_task: 1        # æ¯ä¸ªä»»åŠ¡çš„GPUæ•°
  cpus_per_task: 8        # æ¯ä¸ªä»»åŠ¡çš„CPUæ ¸å¿ƒæ•°
  mem: "32G"              # å†…å­˜
  constraint: "a100|v100" # GPUå‹å·é™åˆ¶
```

### æ•°æ®é…ç½®
```yaml
data:
  benv2_data_dir: "/path/to/data"  # BigEarthNet v2.0 æ•°æ®ç›®å½•
```

### è®­ç»ƒå‚æ•°
```yaml
train:
  args:
    architecture: "resnet18"    # æ¨¡å‹æ¶æ„
    bandconfig: "all"           # æ³¢æ®µé…ç½®ï¼šall, s2, s1, rgb
    batch_size: 32              # æ‰¹å¤§å°
    epochs: 100                 # è®­ç»ƒè½®æ•°
    lr: 0.001                   # å­¦ä¹ ç‡
    seed: 42                    # éšæœºç§å­
    use_wandb: false            # æ˜¯å¦ä½¿ç”¨W&B
    config: "../train_scripts/config.yaml"  # æŒ‡å‘æ­¤é…ç½®æ–‡ä»¶
```

### è¶…å‚æ•°æœç´¢

**æ–¹å¼1: ç½‘æ ¼æœç´¢ï¼ˆç¬›å¡å°”ç§¯ï¼‰**
```yaml
sweep:
  grid:
    lr: [0.001, 0.0003]
    batch_size: [32, 64]
    seed: [42, 123]
```
è¿™ä¼šç”Ÿæˆ 2Ã—2Ã—2 = 8 ä¸ªä½œä¸š

**æ–¹å¼2: åˆ—è¡¨æ–‡ä»¶**
```yaml
sweep:
  list_file: "sweeps.txt"
```

`sweeps.txt` å†…å®¹ç¤ºä¾‹ï¼š
```yaml
{lr: 0.001, batch_size: 32, seed: 42}
{lr: 0.0003, batch_size: 64, seed: 123}
{lr: 0.0001, batch_size: 128, seed: 456}
```

## ğŸ”§ é«˜çº§ç”¨æ³•

### ä½¿ç”¨DINOv3æ¨¡å‹

```yaml
train:
  args:
    architecture: "dinov3-base"
    linear_probe: true  # å†»ç»“backboneï¼Œåªè®­ç»ƒåˆ†ç±»å¤´
```

### ä»æ£€æŸ¥ç‚¹æ¢å¤

```yaml
train:
  args:
    resume_from: "best"  # æˆ– "last" æˆ– "/path/to/checkpoint.ckpt"
```

### ä¸Šä¼ åˆ°HuggingFace Hub

```yaml
train:
  args:
    upload_to_hub: true
    hf_entity: "your-hf-username"
    use_wandb: true
```

### ä½¿ç”¨è‡ªå®šä¹‰é…ç½®æ–‡ä»¶

```bash
python submit.py --config my_config.yaml
python submit.py --config my_config.yaml --sweep
```

### ä½¿ç”¨è‡ªå®šä¹‰sbatchæ¨¡æ¿

```bash
python submit.py --template my_template.sbatch
```

## ğŸ“Š ç›‘æ§ä½œä¸š

```bash
# æŸ¥çœ‹ä½œä¸šé˜Ÿåˆ—
squeue -u $USER

# æŸ¥çœ‹ç‰¹å®šä½œä¸š
squeue -j JOB_ID

# å–æ¶ˆä½œä¸š
scancel JOB_ID

# æŸ¥çœ‹ä½œä¸šè¾“å‡º
tail -f logs/bigearthnet-ft-JOBID.out
```

## ğŸ› æ•…éšœæ’æŸ¥

### ä½œä¸šå¤±è´¥
1. æ£€æŸ¥æ—¥å¿—æ–‡ä»¶ï¼š`logs/bigearthnet-ft-JOBID.err`
2. éªŒè¯æ•°æ®è·¯å¾„ï¼šç¡®ä¿ `benv2_data_dir` æŒ‡å‘æ­£ç¡®çš„æ•°æ®é›†
3. æ£€æŸ¥ç¯å¢ƒï¼šç¡®ä¿ `env_setup.sh` æ­£ç¡®åŠ è½½äº†condaç¯å¢ƒ

### æ•°æ®è·¯å¾„é—®é¢˜
è®­ç»ƒè„šæœ¬ä¼šæŒ‰ä»¥ä¸‹é¡ºåºæŸ¥æ‰¾æ•°æ®ç›®å½•ï¼š
1. å¦‚æœæä¾›äº† `--config` å‚æ•°ï¼Œä»é…ç½®æ–‡ä»¶è¯»å– `data.benv2_data_dir`
2. å¦åˆ™ï¼Œæ ¹æ®hostnameè‡ªåŠ¨é€‰æ‹©ï¼ˆmars, erde, plutoç­‰ï¼‰
3. æœ€åå›é€€åˆ°é»˜è®¤è·¯å¾„

### æäº¤è„šæœ¬æ‰¾ä¸åˆ°sbatch
å¦‚æœçœ‹åˆ° "sbatch command not found"ï¼Œç¡®ä¿ï¼š
1. ä½ åœ¨SLURMé›†ç¾¤ä¸Šè¿è¡Œ
2. SLURMæ¨¡å—å·²åŠ è½½ï¼ˆå¯èƒ½éœ€è¦ `module load slurm`ï¼‰

## ğŸ“š ç¤ºä¾‹å·¥ä½œæµ

### å•æ¬¡å®éªŒ
```bash
# 1. ç¼–è¾‘config.yamlè®¾ç½®å‚æ•°
vim config.yaml

# 2. é¢„è§ˆ
python submit.py --dry-run

# 3. æäº¤
python submit.py

# 4. ç›‘æ§
squeue -u $USER
tail -f logs/bigearthnet-ft-*.out
```

### è¶…å‚æ•°æœç´¢
```bash
# 1. é…ç½®sweepç½‘æ ¼
vim config.yaml  # ç¼–è¾‘ train.sweep.grid

# 2. é¢„è§ˆæ‰€æœ‰ä½œä¸š
python submit.py --sweep --dry-run

# 3. æäº¤å…¨éƒ¨
python submit.py --sweep

# 4. ç›‘æ§å…¨éƒ¨ä½œä¸š
watch -n 10 squeue -u $USER
```

## ğŸ”— ç›¸å…³æ–‡ä»¶

- è®­ç»ƒè„šæœ¬: `../scripts/train_BigEarthNetv2_0.py`
- å·¥å…·å‡½æ•°: `../scripts/utils.py`
- é¡¹ç›®README: `../README.md`
